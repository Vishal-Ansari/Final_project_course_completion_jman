from sklearn.model_selection import train_test_split

# Define features (X) and target (y)
X = df.drop(columns=['Average Score'])  # Adjust this based on your target
y = df['Average Score']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)



from sklearn.ensemble import RandomForestRegressor

# Initialize the model
model = RandomForestRegressor()

# Fit the model
model.fit(X_train, y_train)




from sklearn.metrics import mean_squared_error, r2_score

# Make predictions
y_pred = model.predict(X_test)
import pandas as pd

# Sample DataFrame creation (you already have a DataFrame named df)
# df = pd.DataFrame(...)

# Count the number of courses attempted by each employee
course_count = df['employee_id'].value_counts()
multiple_courses_employees = course_count[course_count > 1].index

# Filter the DataFrame for these employees
filtered_df = df[df['employee_id'].isin(multiple_courses_employees)]



# Group by employee_id and find the index of the course with the lowest average score
least_performance_courses = (
    filtered_df.loc[filtered_df.groupby('employee_id')['Average Score'].idxmin()]
)



# Merging back to get all details, if needed
assigned_courses = pd.merge(df[['employee_id', 'course_id']], 
                            least_performance_courses[['employee_id', 'course_id_x', 'Average Score']],
                            on='employee_id',
                            suffixes=('', '_least'))









# Evaluate
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'MSE: {mse}, RÂ²: {r2}')




from sklearn.model_selection import GridSearchCV

# Example of hyperparameter tuning
param_grid = {
    'n_estimators': [50, 100],
    'max_depth': [None, 10, 20]
}
grid_search = GridSearchCV(RandomForestRegressor(), param_grid, cv=5)
grid_search.fit(X_train, y_train)

print(f'Best parameters: {grid_search.best_params_}')
